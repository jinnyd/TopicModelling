{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Include libraries</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "#for absolute path\n",
    "import os.path\n",
    "#import library\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Read in data and tokenized paragraphs </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = os.path.abspath(os.path.dirname(\"data_clean.csv\"))\n",
    "filepath = os.path.join(mypath, \"data_clean.csv\")\n",
    "\n",
    "#load cleaned data\n",
    "data = pd.read_csv(filepath)\n",
    "\n",
    "content = data['text']\n",
    "def Tokenize(doc):\n",
    "    res = []\n",
    "    for line in doc:\n",
    "        res.append(line.split())\n",
    "    return res\n",
    "\n",
    "tokenizer = Tokenize(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Create doc2vec model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(tokenizer)]\n",
    "model = Doc2Vec(documents, vector_size=50, window=2, min_count=1, workers=2)\n",
    "model.save('doc2vec_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec.load('doc2vec_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vec_story(story, model):\n",
    "    return model.infer_vector(story.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00407842,  0.08297126,  0.00977973,  0.03859513, -0.00843308,\n",
       "        0.00260707,  0.02865642, -0.00713198,  0.06388026,  0.01274039,\n",
       "       -0.0268075 , -0.06243327,  0.03831375,  0.00980393, -0.0968153 ,\n",
       "        0.05342418, -0.04955255,  0.00709607,  0.00893435, -0.02344432,\n",
       "        0.01740087, -0.03707265, -0.02248234, -0.0603975 , -0.01162544,\n",
       "        0.06116146, -0.00656501,  0.022099  , -0.00849097,  0.02633182,\n",
       "       -0.01368344,  0.13734193, -0.02186378, -0.04771705, -0.0376929 ,\n",
       "       -0.05081116, -0.11313038,  0.0160967 , -0.01215811, -0.02896532,\n",
       "       -0.02109678,  0.09197699, -0.02260717, -0.0963128 , -0.02495206,\n",
       "       -0.06155593,  0.0074307 ,  0.10094819, -0.08793638, -0.01581753],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story = \"summer school\"\n",
    "model.infer_vector(story.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = similarity_score(story, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the index of most similar articles \n",
    "def find_article_idx(score, n):\n",
    "\treturn np.argsort(score)[::-1][:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = find_article_idx(test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1897,  744, 3650, 2407, 2458, 1761, 2285, 1357, 1714, 3345])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
